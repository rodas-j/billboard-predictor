---
title: "Stat 21 Final Project - Final Draft"
author: "Rodas Jateno, Sannan Dhillon, Amy Cho"
date: "12/17/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(magrittr) 
library(dplyr)
library(lubridate)
library(ggmosaic)
library(plotROC)
library(tidyverse)
library(patchwork)
library(tidymodels)
library(GGally)
library(rpart)
library(rpart.plot)
library(kknn)
library(plotROC)
```

# Data Cleaning

Before the entire process of data cleaning starts, we are first going to download the dataset and put it in a variable. The dataset in question is pubicly availbe from a link so we will read the CSV off the link directly. 

```{r}
billboard <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-09-14/billboard.csv')
```

Another data we were looking at was the audio features data which is a subset of the billboard data that includes all the songs that appear on Spotify along with their spotify features. We decided to take out songs that have NA because we couldn't find data information for these songs. 
```{r}

audio_features = read.csv("audio_features.csv")
# remove NAs
audio_features_final <- na.omit(audio_features)

#select only important variables in our billboard data
b1 = billboard %>% mutate(date=mdy(week_id), year=year(date))

#order b1 by least recent to most recent 
b1_ordered <- b1 %>% arrange(ymd(b1$date))

```

After we do that we have to find a way to merge the new dataset we made with the original billboard dataset because that dataset contains variables that we will need for our model.
```{r}
#select only important variables in our audio_features data 

f1 = audio_features_final %>% select(spotify_genre, danceability, energy, key, loudness, mode, speechiness, acousticness, instrumentalness, liveness, valence, tempo, time_signature, song_id, spotify_track_popularity, spotify_track_explicit) 

#join the billboard_ordered and audio_features dataset 
joined = b1_ordered %>% right_join(f1, by="song_id")

#added in_billboard = 1 because all songs appeared in billboard
final_data <- mutate(joined, in_billboard = 1)

#final_data shows a clean datatset that only includes important predictors 
```

# Exploring the Data

After we have accomplished the merge, we can now look at interesting EDAs that come up.

```{r}
ggplot(final_data) +
  aes(x = speechiness) +
  geom_histogram(bins = 30L, fill = "#228B22") +
  labs(y = "Number of Songs", title = "Speechiness Frequency") +
  theme_light()
```


```{r}
ggplot(final_data) +
  aes(x = loudness) +
  geom_histogram(bins = 30L, fill = "#228B22") +
  labs(y = "Number of Songs", title = "Loudness Frequency") +
  theme_light()
```

```{r}
ggplot(final_data) +
  aes(x = key) +
  geom_histogram(bins = 30L, fill = "#228B22") +
  labs(y = "Number of Songs", title = "Key Frequency") +
  theme_light()
```

```{r}
ggplot(final_data) +
  aes(x = tempo) +
  geom_histogram(bins = 30L, fill = "#228B22") +
  labs(y = "Number of Songs", title = "Tempo Frequency") +
  theme_light()
```

```{r}
final_data = final_data %>% 
  mutate(year = format(date,"%Y")) %>%
  mutate(decade = floor((strtoi(year))/10)*10) %>%
      group_by(decade)

ggplot(final_data) +
  aes(x = danceability) +
  geom_density(adjust = 1L, fill = "#228B22") +
  labs(y = "Frequency", title = "Danceability vs Frequency") +
  theme_light() +
  facet_wrap(vars(decade))
```

```{r}
ggplot(final_data) +
  aes(x = danceability, y = spotify_track_popularity) +
  geom_point(shape = "circle", alpha = 0.5, size = 0.25, colour = "#228B22") +
  labs(
    x = "Danceability",
    y = "Spotify Popularity",
    title = "Danceability vs Spotify Popularity"
  ) + facet_wrap(vars(decade)) +
  theme_classic() 
```
```{r}

billboard_songs = read.csv("final_data.csv")
random_songs = read.csv("random_songs_playlist5001.csv")
random_songs = subset(random_songs, select = -c(spotify_track_explicit))
random_songs = random_songs %>%
  mutate(song_id = paste(track_name, artist, sep=""))
random_songs = random_songs %>% 
  filter(!song_id %in% billboard_songs$song_id)
random_songs = random_songs %>% 
  rename(spotify_track_explicit = explicit) %>% 
  mutate(in_billboard = 0)
billboard_songs = billboard_songs %>%
  select(c(4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20))
random_songs = random_songs %>%
  select(c(22, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 21, 23))
```
```{r}
colnames(random_songs)
colnames(billboard_songs)
```

```{r}
all_songs = rbind(random_songs, billboard_songs)
all_songs = unique(all_songs)
```
```


# Modelling and Selection

Now that we have seen all the interesting trends in the data we can move on to performing the predictor selection and modelling. We start by performing the forward, backward, and forward-backward selection on the data we currently have.

```{r}
#using forward backward selection

#base model

base_lm = lm(formula = in_billboard ~ 1, data = all_songs)

#full model

full_lm = lm(formula = in_billboard ~ danceability+energy+key+loudness+mode+speechiness +acousticness+instrumentalness+liveness+valence+tempo+time_signature+spotify_track_popularity+ spotify_track_explicit, data = all_songs)
```

```{r}
#forward selection
forward_lm = stats::step(base_lm, scope=list(lower=base_lm, upper=full_lm), direction="forward")
```

```{r}
#backward selection
backward_lm = stats::step(full_lm, scope=list(lower=base_lm, upper=full_lm), direction="backward")
```

```{r}
#forward-backward selection
both_lm = stats::step(base_lm, scope=list(lower=base_lm, upper=full_lm), direction="both")
```

We then proceed to picking the most important variables from the above selection. The predictors we select will be hard conded in the regression model we create in the later stage of the code. In the meantime, we are going to import a dataset that was generated by our Python code in the ipynb file called [Random Songs Generator](https://colab.research.google.com/drive/1QeMKJ-IwPg1IfsCPPZqDzRrk11fscJCr?usp=sharing). This contains a lot of popular songs. We import that data and then 


## Training and Test Dataset
Then we use an algorithm that breaks our all_songs dataset into test and train dataset.

```{r}
#logistic model
all_songs = all_songs %>%
mutate(
  in_billboard_factor = as.factor(in_billboard),
  spotify_track_explicit = ifelse(spotify_track_explicit == "True", 1, 0)
) 

all_songs <- all_songs %>% 
  mutate(id = row_number())
#Check IDs
head(all_songs$id)
#Create training set
train <- all_songs %>% 
  sample_frac(.70)
#Create test set
test  <- anti_join(all_songs, train, by = 'id')
```

## Logistic Regression

```{r}
spotify_glm <- logistic_reg(mode = "classification") %>%
set_engine("glm") %>%
fit(in_billboard_factor ~ danceability+energy+key+loudness+mode+speechiness +acousticness+valence+tempo+time_signature+spotify_track_popularity+ spotify_track_explicit, data = train)

tidy(spotify_glm)
```

## Classification Tree
```{r}
#decision tree

spotify_tree <- decision_tree(mode = "classification") %>%
  set_engine("rpart", control = rpart.control(cp = 0.005)) %>%
  fit(in_billboard_factor ~ danceability+energy+key+loudness+mode+speechiness +acousticness+instrumentalness+liveness+valence+tempo+time_signature+spotify_track_popularity+ spotify_track_explicit, data = train)

library(rpart.plot)
rpart.plot(spotify_tree$fit, extra = 1)
```

```{r}
log_reg_predictions = augment(spotify_glm, new_data = test) %>%
  mutate(model = "logistic") 

tree_predictions = augment(spotify_tree, new_data = test) %>%
  mutate(model = "classification tree")
log_reg_predictions
```


```{r}
all_predictions = log_reg_predictions %>%
  bind_rows(tree_predictions) 
```
## ROC Curves

The ROC Curves we made are using the test datasets to  see if our model is doing well for the test dataset as well as the training dataset.
```{r}
#ROC curves

library(plotROC) #extension of ggplot2
ggplot(all_predictions,
         aes(d = in_billboard, 
         m = .pred_1, 
         col = model)) +
  geom_roc(n.cuts = 10, labelround = 3) + 
  geom_abline(intercept = 0) + 
  labs(x = "False Positive Rate (1 - Specificity)", 
       y = "True Positive Rate (Sensitivity)") +
  theme_bw() + theme_minimal()
```
## Accuracy

For checking accuracy we are going to use the test dataset on both the classification tree and the logistic regression model. 

```{r}
# Logistic Regression Model
augment(spotify_glm, new_data = test) %>%
select(in_billboard, .pred_class) %>%
table()

# Classification Tree
augment(spotify_tree, new_data = test) %>%
select(in_billboard, .pred_class) %>%
table()
```

